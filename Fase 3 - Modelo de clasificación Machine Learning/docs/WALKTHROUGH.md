# Walkthrough - Modelo de Clasificaci√≥n Machine Learning para Osteoporosis

## Resumen del Proyecto

Este proyecto desarrolla un modelo de machine learning para clasificar c√©lulas mesenquimales (MSC) como:
- **Clase 0**: Control (c√©lulas normales)
- **Clase 1**: Osteoporosis Primaria (OP)

---

## üìä Dataset

### Datos Combinados
- **Total de muestras**: 37
  - Original: 28 muestras
  - Validaci√≥n externa (GSE35958): 9 muestras
- **Features (genes)**: 33 genes candidatos
- **Distribuci√≥n de clases**:
  - Clase 0 (Control): 23 muestras (62%)
  - Clase 1 (OP): 14 muestras (38%)

### Genes Candidatos
Los 33 genes fueron seleccionados de las Fases I y II del proyecto basados en an√°lisis diferencial y significancia biol√≥gica.

---

## üî¨ Metodolog√≠a

### 1. Preprocesamiento
- **Normalizaci√≥n**: StandardScaler (media=0, std=1)
- **Alineaci√≥n de features**: Asegurar que ambos datasets tengan las mismas columnas
- **Transformaci√≥n logar√≠tmica**: log2(x+1) aplicada cuando fue necesario

### 2. Estrategia de Validaci√≥n
**Validaci√≥n Cruzada Estratificada (5-Fold)**
- Divide el dataset en 5 grupos
- Mantiene la proporci√≥n de clases en cada fold
- Cada muestra se usa exactamente 1 vez para validaci√≥n
- M√©tricas reportadas son el **promedio de 5 evaluaciones**

### 3. Modelos Evaluados
1. **Logistic Regression** (Modelo m√°s explicable)
2. **Random Forest**
3. **SVM (Linear)**
4. **Decision Tree**

---

## üìà Resultados

### Cross-Validation (5-Fold) - Dataset Combinado

| Modelo | Accuracy | Precision | Recall | F1 | AUC |
|--------|----------|-----------|--------|----|-----|
| **Logistic Regression** ‚ú® | **1.000** | **1.000** | **1.000** | **1.000** | **1.000** |
| Random Forest | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |
| SVM (Linear) | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |
| Decision Tree (depth=6) | 0.921 | 0.900 | 0.933 | 0.903 | 0.927 |

### Conclusiones de Rendimiento
1. **Logistic Regression, Random Forest y SVM (Linear)** obtienen m√©tricas perfectas (100%)
2. **Decision Tree (depth=6)** tiene un rendimiento muy bueno (92.1% accuracy)
3. Todos los modelos lineales son capaces de separar perfectamente las clases
4. El √°rbol de decisi√≥n m√°s profundo captura mejor los patrones complejos

---

## üéØ Modelo Seleccionado: Logistic Regression

### Razones para la Selecci√≥n
‚úÖ **M√°xima Explicabilidad**: Los coeficientes son directamente interpretables  
‚úÖ **Rendimiento Perfecto**: 100% en todas las m√©tricas  
‚úÖ **Simplicidad**: Modelo lineal f√°cil de entender y comunicar  
‚úÖ **Robustez**: Mejor generalizaci√≥n potencial que modelos no lineales

### Top 5 Genes M√°s Importantes (Logistic Regression)

| # | Gen | Coeficiente (Abs) | Interpretaci√≥n |
|---|-----|-------------------|----------------|
| 1 | **SOX11** | 1.3473 | Factor de transcripci√≥n, altamente discriminativo |
| 2 | **DDIT4L** | 0.2251 | Relacionado con estr√©s celular |

**Nota**: Solo 2 genes muestran coeficientes significativos, sugiriendo que estos son los marcadores clave.

---

## üìâ An√°lisis de Reducci√≥n Dimensional (PCA)

### Resultados PCA
- **PC1**: Explica 30.1% de la varianza
- **PC2**: Explica 20.2% de la varianza
- **Total**: 50.3% de varianza explicada con 2 componentes

### Visualizaciones Generadas
1. **decision_boundaries_pca.png**: L√≠mites de decisi√≥n en espacio 2D
   - Muestra c√≥mo cada modelo separa las clases
   - Logistic Regression crea un l√≠mite lineal claro
   - Decision Tree crea regiones rectangulares

2. **decision_tree_visualization.png**: √Årbol de decisi√≥n completo
   - Muestra las reglas de decisi√≥n basadas en genes espec√≠ficos
   - Profundidad m√°xima: 3 niveles para interpretabilidad

3. **feature_importance_comparison.png**: Comparaci√≥n de importancia
   - Logistic Regression: Coeficientes absolutos
   - Decision Tree: Importancia basada en Gini

---

## üå≥ Decision Tree - An√°lisis Complementario

### Rendimiento (depth=6)
- **Accuracy**: 92.1%
- **Precision**: 90.0%
- **Recall**: 93.3%
- **F1**: 90.3%
- **AUC**: 92.7%

### Ventajas del Decision Tree
‚úÖ Reglas f√°ciles de interpretar: "Si GEN_X > valor, entonces Clase 1"  
‚úÖ No requiere normalizaci√≥n  
‚úÖ Captura relaciones no lineales  
‚úÖ **Rendimiento mejorado**: Con profundidad 6 alcanza 92.1% accuracy

### Observaciones
‚úîÔ∏è Mayor profundidad permite capturar patrones m√°s complejos  
‚úîÔ∏è Mantiene alto recall (93.3%) - detecta la mayor√≠a de casos positivos  
‚ö†Ô∏è A√∫n ligeramente inferior a modelos lineales (92% vs 100%)  
‚ö†Ô∏è Mayor profundidad aumenta riesgo de overfitting (monitorear con datos externos)  

---

## üîç Insights Biol√≥gicos

### Gen SOX11
- **Coeficiente m√°s alto** en Logistic Regression
- **Rol biol√≥gico**: Factor de transcripci√≥n involucrado en diferenciaci√≥n celular
- **Implicaci√≥n**: Expresi√≥n diferencial clara entre MSC normales y con osteoporosis

### Gen DDIT4L
- **Segundo coeficiente m√°s alto**
- **Rol biol√≥gico**: Regulador de respuesta al estr√©s y mTOR signaling
- **Implicaci√≥n**: Puede reflejar estr√©s metab√≥lico en c√©lulas con osteoporosis

---

## üìÅ Archivos Generados

### Modelos
- `final_explainable_model.pkl`: Modelo Logistic Regression final
- `final_scaler.pkl`: StandardScaler ajustado a los datos
- `best_model_combined.pkl`: Mejor modelo (Logistic Regression)
- `scaler_combined.pkl`: Scaler para modelo combinado

### Visualizaciones
- `decision_boundaries_pca.png`: L√≠mites de decisi√≥n en 2D
- `decision_tree_visualization.png`: √Årbol de decisi√≥n
- `feature_importance_comparison.png`: Comparaci√≥n de importancia
- `feature_importance.png`: Importancia de features (entrenamiento inicial)

### Scripts
- `train_model.py`: Entrenamiento inicial con datos originales
- `train_model_combined.py`: Entrenamiento con datos combinados + CV
- `validate_model.py`: Validaci√≥n en dataset externo
- `model_analysis_visualization.py`: An√°lisis completo y visualizaciones

---

## üéì Recomendaciones

### Para Uso Cl√≠nico/Investigaci√≥n
1. **Validar con m√°s datos externos**: 37 muestras es limitado
2. **Validaci√≥n prospectiva**: Probar con nuevos pacientes
3. **An√°lisis de SOX11**: Investigar m√°s a fondo su rol en osteoporosis

### Para Mejora del Modelo
1. **Aumentar dataset**: Buscar m√°s datasets p√∫blicos de MSC
2. **Feature engineering**: Considerar ratios o combinaciones de genes
3. **Validaci√≥n externa independiente**: Probar en cohorte completamente diferente

### Limitaciones
‚ö†Ô∏è **Dataset peque√±o**: 37 muestras pueden no representar toda la variabilidad  
‚ö†Ô∏è **Posible overfitting**: M√©tricas perfectas sugieren revisar con m√°s datos  
‚ö†Ô∏è **Batch effects**: Datos de fuentes diferentes pueden tener variaciones t√©cnicas  

---

## üìß Pr√≥ximos Pasos

1. ‚úÖ Modelo entrenado y validado
2. ‚úÖ Visualizaciones generadas
3. ‚¨ú Validaci√≥n en cohorte externa independiente
4. ‚¨ú Estudio funcional de SOX11 y DDIT4L
5. ‚¨ú Publicaci√≥n de resultados

---

## üî¨ Conclusi√≥n Final

Se desarroll√≥ exitosamente un modelo de **Logistic Regression** con **100% de accuracy** para clasificar c√©lulas mesenquimales seg√∫n su estado (Normal vs Osteoporosis Primaria). 

**Los genes SOX11 y DDIT4L** emergen como los marcadores m√°s discriminativos, sugiriendo su potencial como biomarcadores para diagn√≥stico temprano de osteoporosis.

El modelo es **altamente explicable** y puede ser traducido directamente a reglas cl√≠nicas interpretables.

---

*Fecha de an√°lisis: Noviembre 2025*  
*Proyecto: Bioinform√°tica Avanzada - HMSC Predicci√≥n*
